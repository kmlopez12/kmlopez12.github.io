---
layout: post
title: Project 2 Blog Post
---

### Project Summary  
#Intro  
This project uses the bike sharing data set, day.csv, that's located *[here](https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset)* and contains 731 observations with 15 attributes. For modeling, the response variable is the count of total rental bikes rented (*cnt*) and 11 of the 14 remaining variables will be considered for predictor variables. Variables *casual* and *registered* are omitted and analysis are performed on each *weekday* variable. The 11 remaining variables include values for date, season, year, month, holiday, working day, weather, temperature, feeling temperature, humidity, and wind speed.  
The purpose of this analysis is to fit two different tree models and select the best one based on the appropriate criteria. This report will be automated to run on the data set for each day of the week, starting with Sunday at 0, Monday at 1, and so on.  
Many methods I'll use come from a variety of packages installed in this first code chunk. First I will read in the data and randomly separate it into the training set and testing set, with 70% of the data going into the traiing set. Then I will create some summary statistics and various data plots to view variable relationships and narrow down the predictor variables. Lastly, I will train and fit the models to compare them and pick the final model.  
To begin, necessary libraries are loaded so their functions are accessible and global variables are set.  
#Data  
The dataset is read in using a relative path and saved as an object. The weekday variable is converted to a factor with the day values replacing their corresponding number, and then the weekday variable is used to filter the data for each day of the week. The data is then randomly split into a training and testing set, where 70% of the data goes into the training set and the remaining 30% goes into the testing set.  
#Summarizations  
Just to get an overview of the data, I first look at the summary of all variables, and the distribution of the rental bike counts. Then I delve deeper into the variable relationships with the response variable, count, and with each other using ggpairs. These correlations will help me narrow down which variables to include in the tree models, but I can also view their corresponding scatterplots and density curves.
Various predictor variables have interactions with each other, and I want to focus on those with the lower correlation values with each other but higher correlations with the response. These variables include such as year, temperature, and feeling temperature. The date, season, and month variables will be omitted from further analysis because of their stronger correlations with other variables, and working day will be omitted for its weak correlation with count. The temperature and feeling temperature have a very strong correlation so I'll only keep feeling temperature for it's slightly stronger correlation with the response variable, and analyze it alongside the year variable. These variables were chosen using the `weekday = Monday` data, and will be used for all other days to keep analyses consistent.  
#Modeling  
Next I will utilize the `caret` package to create two tree models with the training set and then predict each on the testing set, after reducing both sets to include only the variables of interest. The models are based on the response variable, *cnt*, being a continuous variable. The predictors are *yr* and *atemp*, which are categorical (0: 2011, 1: 2012) and continuous variables, respectively.  

The first model is a non-ensemble tree-based model chosen using leave-one-out cross-validation, and the second model is a boosted tree model chosen using 12-fold cross-validation. Just in case, and for good practice, the predictor variables are standardize via centering and scaling. Each model is then predicted on using the training set, and their performances are compared via root mean square error (RMSE) and/or mean absolute error (MAE) values.

The model with the lowest RMSE and/or lowest MAE value should be used as the final model. The instructor later asked us to focus on MAE, so for the Monday data, the better model is the boosted tree model.

### Github Pages Repo Link  
My project 2 Github pages repo can be accessed [here](https://github.com/kmlopez12/ST558-Project2).

### What would you do differently?  
Given more time, I would like to find a way to incorporate parallel programming to create the reports simultaneously and faster. Then it may be nice to delve into the hours dataset to find any trends of usage during different times of the days.

### What was the most difficult part for you?  
I believe I had the most trouble with automating the rending of the document to create a report for each day of the week. I was able to follow the video and lecture on this topic but didn't see it done until this project. Once I figured out how to properly compose the Rscript and run it, it was relieveing to watch the reports populate.

### What are your big take-aways from this project?  
My big takeaways are that redundancy is greatly reduced with automation of R markdown documents. It was nice to leave the machine running and not have to manually create a file for each weekday. I can imagine this being scaled up to daily reports, if desired by a supervisor, so automation would make these types of tasks easier. I also could see how parallel programming could fit into these types of tasks as well. The reports are independent of each other and would generate even faster if done simultaneuously on different nodes.
