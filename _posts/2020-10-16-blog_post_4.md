---
layout: post
title: Project 2 Blog Post
---

### Project Summary  
This project uses the bike sharing data set, day.csv, located *[here](https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset)*, and contains 731 observations with 15 attributes. For modeling, the response variable is the count of total rental bikes rented (*cnt*) and 11 of the 14 remaining variables will be considered for predictor variables. Variables *casual* and *registered* are omitted, and analysis are performed per each *weekday* value. The 11 remaining variables include values for date, season, year, month, holiday, working day, weather, temperature, feeling temperature, humidity, and wind speed. The reports will be automated to run on the data set for each day of the week.  
The purpose of the analysis is to fit two different tree models and select the best one based on the appropriate criteria. The data is read in and randomly split into a training set and testing set. The training set is explored via summarization tables and plots to select variables for predicting. The two models are fit using the training set and then predicted on using the testing set. The model with smaller root mean square error and/or mean absolute error is chosen as the final model.  

### Github Pages Repo Link  
My project 2 Github pages repo can be accessed [here](https://github.com/kmlopez12/ST558-Project2).

### What would you do differently?  
Given more time, I would like to find a way to incorporate parallel programming to create the reports simultaneously and faster. Then it may be nice to delve into the hours dataset to find any trends of usage during different times of the days.

### What was the most difficult part for you?  
I believe I had the most trouble with automating the rending of the document to create a report for each day of the week. I was able to follow the video and lecture on this topic but didn't see it done until this project. Once I figured out how to properly compose the Rscript and run it, it was relieveing to watch the reports populate.

### What are your big take-aways from this project?  
My big takeaways are that redundancy is greatly reduced with automation of R markdown documents. It was nice to leave the machine running and not have to manually create a file for each weekday. I can imagine this being scaled up to daily reports, if desired by a supervisor, so automation would make these types of tasks easier. I also could see how parallel programming could fit into these types of tasks as well. The reports are independent of each other and would generate even faster if done simultaneuously on different nodes.
